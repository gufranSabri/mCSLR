work_dir: work_dir/v4
mode: train
batch_size: 8
epochs: 50
device: mps
seed: 42
config: configs/baseline.yaml
slurm_mode: False
data_path: /Users/gufran/Developer/data/sign
datasets: ['CSL-Daily', 'phoenix2014-T']
training: {'validation': {'recognition': {'beam_size': 1}, 'translation': {}}, 'optimization': {'patience': 16, 'optimizer': 'Adam', 'learning_rate': {'default': 0.0001}, 'weight_decay': 0.001, 'betas': [0.9, 0.998], 'scheduler': {'name': 'plateau', 'patience': 5, 'factor': 0.2, 'step': [20, 25, 30, 35, 40, 45]}, 't_max': 100}}
testing: {'recognition': {'beam_size': 5}, 'translation': {}, 'optimization': {'optimizer': 'Adam', 'learning_rate': {'default': 0.001}, 'weight_decay': 0.001, 'betas': [0.9, 0.998], 'scheduler': 'plateau', 't_max': 100}}
model: {'RecognitionNetwork': {'input_type': 'keypoint', 'GlossTokenizer': {'gloss2id_file': 'data/CSL-Daily_phoenix2014-T/gloss2ids.pkl'}, 'DSTA-Net': {'net': [[64, 64, 16, 7, 2], [64, 64, 16, 3, 1], [64, 128, 32, 3, 1], [128, 128, 32, 3, 1], [128, 256, 64, 3, 2], [256, 256, 64, 3, 1], [256, 256, 64, 3, 1], [256, 256, 64, 3, 1]], 'body': [0, 1, 3, 5, 7, 9, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 2, 4, 6, 8, 10, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 23, 26, 29, 33, 36, 39, 41, 43, 46, 48, 53, 56, 59, 62, 65, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81], 'left': [0, 1, 3, 5, 7, 9, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111], 'right': [0, 2, 4, 6, 8, 10, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132], 'face': [23, 26, 29, 33, 36, 39, 41, 43, 46, 48, 53, 56, 59, 62, 65, 68, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81], 'mouth': [71, 72, 73, 74, 75, 76, 77, 79, 80, 81]}, 'hidden_size': 1024, 'body_visual_head': {'input_size': 256, 'hidden_size': 1024, 'ff_size': 2048, 'ff_kernelsize': [3, 3]}, 'fuse_visual_head': {'input_size': 1024, 'hidden_size': 1024, 'ff_size': 2048, 'ff_kernelsize': [3, 3]}, 'left_visual_head': {'input_size': 512, 'hidden_size': 1024, 'ff_size': 2048, 'ff_kernelsize': [3, 3]}, 'right_visual_head': {'input_size': 512, 'hidden_size': 1024, 'ff_size': 2048, 'ff_kernelsize': [3, 3]}}}
resume_training: False


Datasets loaded successfully.
Number of training samples: 25495
Number of dev samples: 1594
Number of test samples: 1816

Model initialized with 236.22 million parameters.

Optimizer: AdamW
Scheduler: MultiStepLR (Type: epoch)

Starting training...

Epoch [0/50] - LR: 0.000100
